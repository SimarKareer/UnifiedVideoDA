{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cbef123c-89ad-4bbb-9da2-b463d0b3ef8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/flash1/skareer6/miniconda3/envs/mmseg/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from mmseg.datasets.viperSeq import ViperSeqDataset\n",
    "from mmseg.datasets.viper import ViperDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from functools import partial\n",
    "from mmcv.parallel import collate\n",
    "from mmseg.core.evaluation.metrics import flow_prop_iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02bc389a-164f-45c4-8846-7bd7155689f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset settings\n",
    "dataset_type = 'ViperDataset'\n",
    "data_root = '/srv/share4/datasets/VIPER/'\n",
    "\n",
    "#imagenet values\n",
    "img_norm_cfg = dict(\n",
    "    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\n",
    "\n",
    "#crop size from the da-vsn paper code\n",
    "crop_size = (720, 1280)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3184e14e-86fa-494d-80eb-96a802476b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_pipeline = [\n",
    "#     dict(type='LoadImageFromFile'),\n",
    "#     dict(type='LoadAnnotations'),\n",
    "#     dict(type='Resize', img_scale=(2048, 1024), ratio_range=(0.5, 2.0)),\n",
    "#     dict(type='RandomCrop', crop_size=crop_size, cat_max_ratio=0.75),\n",
    "#     dict(type='RandomFlip', prob=0.5),\n",
    "#     dict(type='PhotoMetricDistortion'),\n",
    "#     dict(type='Normalize', **img_norm_cfg),\n",
    "#     dict(type='Pad', size=crop_size, pad_val=0, seg_pad_val=255),\n",
    "#     dict(type='DefaultFormatBundle'),\n",
    "#     dict(type='Collect', keys=['img', 'gt_semantic_seg']),\n",
    "# ]\n",
    "test_pipeline = {\n",
    "    \"im_load_pipeline\": [\n",
    "        dict(type='LoadImageFromFile'),\n",
    "        dict(type='LoadAnnotations'),\n",
    "    ],\n",
    "    \"load_no_ann_pipeline\": [\n",
    "        dict(type='LoadImageFromFile'),\n",
    "    ],\n",
    "    \"load_flow_pipeline\": [\n",
    "        dict(type='LoadFlowFromFile'),\n",
    "    ],\n",
    "    \"shared_pipeline\": [\n",
    "        # dict(type='Resize', keep_ratio=True, img_scale=(1080, 1920)),\n",
    "        # dict(type='RandomCrop', crop_size=crop_size, cat_max_ratio=0.75),\n",
    "        dict(type='RandomFlip', prob=0.0),\n",
    "    ],\n",
    "    \"im_pipeline\": [\n",
    "        # dict(type='PhotoMetricDistortion'),\n",
    "        dict(type='Normalize', **img_norm_cfg),\n",
    "        # dict(type='Pad', size=crop_size, pad_val=0, seg_pad_val=255),\n",
    "        # dict(type='DefaultFormatBundle'),\n",
    "        dict(type='ImageToTensor', keys=['img']),\n",
    "        dict(type='Collect', keys=['img', 'gt_semantic_seg'])#, meta_keys=[]),\n",
    "    ],\n",
    "    \"flow_pipeline\": [\n",
    "        dict(type='Pad', size=crop_size, pad_val=0, seg_pad_val=255),\n",
    "        dict(type='DefaultFormatBundle'), #I don't know what this is\n",
    "        dict(type='Collect', keys=['img', 'gt_semantic_seg'])#, meta_keys=[]),\n",
    "    ]\n",
    "}\n",
    "\n",
    "img_dir = '/srv/share4/datasets/VIPER/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df669099-a8ce-493b-90c9-aae17bee004b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-15 11:15:49,575 - mmseg - INFO - Loaded 4959 images\n",
      "2022-11-15 11:15:49,646 - mmseg - INFO - Loaded 4959 images\n",
      "2022-11-15 11:15:49,654 - mmseg - INFO - Loaded 4959 images\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PL:  {'im_load_pipeline': [{'type': 'LoadImageFromFile'}, {'type': 'LoadAnnotations'}], 'load_no_ann_pipeline': [{'type': 'LoadImageFromFile'}], 'load_flow_pipeline': [{'type': 'LoadFlowFromFile'}], 'shared_pipeline': [{'type': 'RandomFlip', 'prob': 0.0}], 'im_pipeline': [{'type': 'Normalize', 'mean': [123.675, 116.28, 103.53], 'std': [58.395, 57.12, 57.375], 'to_rgb': True}, {'type': 'ImageToTensor', 'keys': ['img']}, {'type': 'Collect', 'keys': ['img', 'gt_semantic_seg']}], 'flow_pipeline': [{'type': 'Pad', 'size': (720, 1280), 'pad_val': 0, 'seg_pad_val': 255}, {'type': 'DefaultFormatBundle'}, {'type': 'Collect', 'keys': ['img', 'gt_semantic_seg']}]}\n",
      "type PL:  <class 'dict'>\n",
      "type PL:  False\n"
     ]
    }
   ],
   "source": [
    "viper = ViperSeqDataset(\n",
    "        data_root=data_root,\n",
    "        img_dir='val/img',\n",
    "        ann_dir='val/cls',\n",
    "        split='splits/val.txt',\n",
    "        pipeline=test_pipeline,\n",
    "        frame_offset=1,\n",
    "        flow_dir=\"/srv/share4/datasets/VIPER_Flowv3/val/flow_occ\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f88a8b58-1aac-41a7-9253-cbc6752b3440",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "made dl\n",
      "{'img_metas': [DataContainer([[{'filename': '/srv/share4/datasets/VIPER/val/img/001/001_00010.jpg', 'ori_filename': '001/001_00010.jpg', 'img_shape': (1080, 1920, 3), 'ori_shape': (1080, 1920, 3), 'pad_shape': (1080, 1920, 3), 'scale_factor': 1.0, 'img_norm_cfg': {'mean': array([123.675, 116.28 , 103.53 ], dtype=float32), 'std': array([58.395, 57.12 , 57.375], dtype=float32), 'to_rgb': True}, 'flip': False, 'flip_direction': 'horizontal'}]])], 'img': [tensor([[[[-1.4500, -1.4500, -1.4329,  ...,  1.4612,  1.4612,  1.4612],\n",
      "          [-1.3302, -1.3473, -1.3644,  ...,  1.4612,  1.4612,  1.4612],\n",
      "          [-1.1932, -1.2103, -1.2445,  ...,  1.4612,  1.4612,  1.4612],\n",
      "          ...,\n",
      "          [ 1.3242,  1.3584,  1.4098,  ...,  2.0948,  2.0948,  2.0948],\n",
      "          [ 1.3413,  1.3584,  1.4098,  ...,  2.0948,  2.0948,  2.0948],\n",
      "          [ 1.3413,  1.3584,  1.3927,  ...,  2.0948,  2.0948,  2.0948]],\n",
      "\n",
      "         [[-1.3354, -1.3354, -1.3179,  ...,  1.7458,  1.7458,  1.7458],\n",
      "          [-1.2129, -1.2304, -1.2479,  ...,  1.7458,  1.7458,  1.7458],\n",
      "          [-1.0728, -1.0903, -1.1254,  ...,  1.7458,  1.7458,  1.7458],\n",
      "          ...,\n",
      "          [ 1.0805,  1.1155,  1.1681,  ...,  2.1660,  2.1660,  2.1660],\n",
      "          [ 1.0980,  1.1155,  1.1681,  ...,  2.1660,  2.1660,  2.1660],\n",
      "          [ 1.0980,  1.1155,  1.1506,  ...,  2.1660,  2.1660,  2.1660]],\n",
      "\n",
      "         [[-1.0376, -1.0376, -1.0201,  ...,  2.0997,  2.0997,  2.0997],\n",
      "          [-0.9156, -0.9330, -0.9504,  ...,  2.0997,  2.0997,  2.0997],\n",
      "          [-0.7761, -0.7936, -0.8284,  ...,  2.0997,  2.0997,  2.0997],\n",
      "          ...,\n",
      "          [ 0.7054,  0.7402,  0.7925,  ...,  1.9951,  1.9951,  1.9951],\n",
      "          [ 0.7228,  0.7402,  0.7925,  ...,  1.9951,  1.9951,  1.9951],\n",
      "          [ 0.7228,  0.7402,  0.7751,  ...,  1.9951,  1.9951,  1.9951]]]])], 'gt_semantic_seg': [tensor([[[10, 10, 10,  ...,  2,  2,  2],\n",
      "         [10, 10, 10,  ...,  2,  2,  2],\n",
      "         [10, 10, 10,  ...,  2,  2,  2],\n",
      "         ...,\n",
      "         [10, 10, 10,  ..., 24, 24, 24],\n",
      "         [10, 10, 10,  ..., 24, 24, 24],\n",
      "         [10, 10, 10,  ..., 24, 24, 24]]], dtype=torch.uint8)], 'flow': [tensor([[[[-94.3125, -94.1875, -94.0625,  ...,   0.0000,   0.0000,   0.0000],\n",
      "          [-94.2500, -94.1250, -94.0000,  ...,   0.0000,   0.0000,   0.0000],\n",
      "          [-94.1875, -94.0625, -93.9375,  ...,   0.0000,   0.0000,   0.0000],\n",
      "          ...,\n",
      "          [  0.0000,   0.0000,   0.0000,  ...,   0.9375,   0.8906,   0.8906],\n",
      "          [  0.0000,   0.0000,   0.0000,  ...,   0.9375,   0.8906,   0.8906],\n",
      "          [  0.0000,   0.0000,   0.0000,  ...,   0.9375,   0.8750,   0.8750]],\n",
      "\n",
      "         [[-34.5000, -34.4688, -34.4688,  ...,   0.0000,   0.0000,   0.0000],\n",
      "          [-34.3750, -34.3750, -34.3438,  ...,   0.0000,   0.0000,   0.0000],\n",
      "          [-34.2500, -34.2500, -34.2188,  ...,   0.0000,   0.0000,   0.0000],\n",
      "          ...,\n",
      "          [  0.0000,   0.0000,   0.0000,  ...,   6.0469,   6.0469,   6.0469],\n",
      "          [  0.0000,   0.0000,   0.0000,  ...,   6.0469,   6.0469,   6.0469],\n",
      "          [  0.0000,   0.0000,   0.0000,  ...,   6.0469,   6.0469,   6.0469]]]])], 'imtk': [tensor([[[[-1.5014, -1.4500, -1.4158,  ...,  1.4954,  1.4954,  1.4954],\n",
      "          [-1.3815, -1.3987, -1.4329,  ...,  1.4954,  1.4954,  1.4954],\n",
      "          [-1.1760, -1.2274, -1.2959,  ...,  1.4954,  1.4954,  1.4954],\n",
      "          ...,\n",
      "          [ 1.2043,  1.2043,  1.2214,  ...,  2.0948,  2.0948,  2.0948],\n",
      "          [ 1.2043,  1.2043,  1.2043,  ...,  2.0948,  2.0948,  2.0948],\n",
      "          [ 1.2043,  1.2043,  1.2043,  ...,  2.0948,  2.0948,  2.0948]],\n",
      "\n",
      "         [[-1.3529, -1.3004, -1.2654,  ...,  1.7458,  1.7458,  1.7458],\n",
      "          [-1.2304, -1.2479, -1.2829,  ...,  1.7458,  1.7458,  1.7458],\n",
      "          [-1.0728, -1.1078, -1.1954,  ...,  1.7458,  1.7458,  1.7458],\n",
      "          ...,\n",
      "          [ 1.1155,  1.1155,  1.1331,  ...,  2.1660,  2.1660,  2.1660],\n",
      "          [ 1.1155,  1.1155,  1.1155,  ...,  2.1660,  2.1660,  2.1660],\n",
      "          [ 1.1155,  1.1155,  1.1155,  ...,  2.1660,  2.1660,  2.1660]],\n",
      "\n",
      "         [[-0.9678, -0.9156, -0.8807,  ...,  2.0300,  2.0300,  2.0300],\n",
      "          [-0.8458, -0.8981, -0.8981,  ...,  2.0300,  2.0300,  2.0300],\n",
      "          [-0.7064, -0.7936, -0.8284,  ...,  2.0300,  2.0300,  2.0300],\n",
      "          ...,\n",
      "          [ 0.6879,  0.6879,  0.7054,  ...,  1.9951,  1.9951,  1.9951],\n",
      "          [ 0.6879,  0.6879,  0.6879,  ...,  1.9951,  1.9951,  1.9951],\n",
      "          [ 0.6879,  0.6879,  0.6879,  ...,  1.9951,  1.9951,  1.9951]]]])], 'imtk_gt_semantic_seg': [tensor([[[[[[10, 10, 10,  ...,  2,  2,  2],\n",
      "            [10, 10, 10,  ...,  2,  2,  2],\n",
      "            [10, 10, 10,  ...,  2,  2,  2],\n",
      "            ...,\n",
      "            [10, 10, 10,  ..., 24, 24, 24],\n",
      "            [10, 10, 10,  ..., 24, 24, 24],\n",
      "            [10, 10, 10,  ..., 24, 24, 24]]]]]], dtype=torch.uint8)]}\n",
      "{'img_metas': [DataContainer([[{'filename': '/srv/share4/datasets/VIPER/val/img/001/001_00020.jpg', 'ori_filename': '001/001_00020.jpg', 'img_shape': (1080, 1920, 3), 'ori_shape': (1080, 1920, 3), 'pad_shape': (1080, 1920, 3), 'scale_factor': 1.0, 'img_norm_cfg': {'mean': array([123.675, 116.28 , 103.53 ], dtype=float32), 'std': array([58.395, 57.12 , 57.375], dtype=float32), 'to_rgb': True}, 'flip': False, 'flip_direction': 'horizontal'}]])], 'img': [tensor([[[[1.7009, 1.7009, 1.7009,  ..., 1.6153, 1.6153, 1.6153],\n",
      "          [1.7009, 1.7009, 1.7009,  ..., 1.6153, 1.6153, 1.6153],\n",
      "          [1.7009, 1.7009, 1.7009,  ..., 1.6153, 1.6153, 1.6153],\n",
      "          ...,\n",
      "          [1.9407, 1.8893, 1.8037,  ..., 2.0605, 2.0605, 2.0434],\n",
      "          [1.8208, 1.7694, 1.7180,  ..., 2.0605, 2.0605, 2.0605],\n",
      "          [1.6667, 1.6324, 1.5982,  ..., 2.0605, 2.0605, 2.0605]],\n",
      "\n",
      "         [[1.9384, 1.9384, 1.9384,  ..., 1.8683, 1.8683, 1.8683],\n",
      "          [1.9384, 1.9384, 1.9384,  ..., 1.8683, 1.8683, 1.8683],\n",
      "          [1.9384, 1.9384, 1.9384,  ..., 1.8683, 1.8683, 1.8683],\n",
      "          ...,\n",
      "          [1.8508, 1.7983, 1.7108,  ..., 2.1134, 2.1134, 2.0959],\n",
      "          [1.7283, 1.6758, 1.6232,  ..., 2.1134, 2.1134, 2.1134],\n",
      "          [1.5707, 1.5357, 1.5007,  ..., 2.1134, 2.1134, 2.1134]],\n",
      "\n",
      "         [[2.1346, 2.1346, 2.1346,  ..., 2.1520, 2.1520, 2.1520],\n",
      "          [2.1346, 2.1346, 2.1346,  ..., 2.1520, 2.1520, 2.1520],\n",
      "          [2.1346, 2.1346, 2.1346,  ..., 2.1520, 2.1520, 2.1520],\n",
      "          ...,\n",
      "          [1.4897, 1.4374, 1.3502,  ..., 1.9951, 1.9951, 1.9777],\n",
      "          [1.3677, 1.3154, 1.2631,  ..., 1.9951, 1.9951, 1.9951],\n",
      "          [1.2108, 1.1759, 1.1411,  ..., 1.9951, 1.9951, 1.9951]]]])], 'gt_semantic_seg': [tensor([[[ 2,  2,  2,  ...,  2,  2,  2],\n",
      "         [ 2,  2,  2,  ...,  2,  2,  2],\n",
      "         [ 2,  2,  2,  ...,  2,  2,  2],\n",
      "         ...,\n",
      "         [ 3,  3,  3,  ..., 24, 24, 24],\n",
      "         [ 3,  3,  3,  ..., 24, 24, 24],\n",
      "         [ 3,  3,  3,  ..., 24, 24, 24]]], dtype=torch.uint8)], 'flow': [tensor([[[[-127.5000, -127.1875, -126.9375,  ...,    0.0000,    0.0000,\n",
      "              0.0000],\n",
      "          [-127.4375, -127.1875, -126.8750,  ...,    0.0000,    0.0000,\n",
      "              0.0000],\n",
      "          [-127.4375, -127.1250, -126.8750,  ...,    0.0000,    0.0000,\n",
      "              0.0000],\n",
      "          ...,\n",
      "          [   0.0000,    0.0000,    0.0000,  ...,   -0.1875,   -0.2969,\n",
      "             -0.2969],\n",
      "          [   0.0000,    0.0000,    0.0000,  ...,   -0.1875,   -0.2969,\n",
      "             -0.2969],\n",
      "          [   0.0000,    0.0000,    0.0000,  ...,   -0.1875,   -0.3594,\n",
      "             -0.3594]],\n",
      "\n",
      "         [[ -65.3750,  -65.3125,  -65.2500,  ...,    0.0000,    0.0000,\n",
      "              0.0000],\n",
      "          [ -65.2500,  -65.1875,  -65.0625,  ...,    0.0000,    0.0000,\n",
      "              0.0000],\n",
      "          [ -65.0625,  -65.0000,  -64.9375,  ...,    0.0000,    0.0000,\n",
      "              0.0000],\n",
      "          ...,\n",
      "          [   0.0000,    0.0000,    0.0000,  ...,    1.8750,    1.8750,\n",
      "              1.8750],\n",
      "          [   0.0000,    0.0000,    0.0000,  ...,    1.8750,    1.8750,\n",
      "              1.8750],\n",
      "          [   0.0000,    0.0000,    0.0000,  ...,    1.8750,    1.8750,\n",
      "              1.8750]]]])], 'imtk': [tensor([[[[-1.0904, -0.9877, -1.1247,  ...,  1.5982,  1.5982,  1.5982],\n",
      "          [-1.0562, -1.0390, -1.1760,  ...,  1.5982,  1.5982,  1.5982],\n",
      "          [-1.0219, -1.1075, -1.1932,  ...,  1.5982,  1.5982,  1.5982],\n",
      "          ...,\n",
      "          [ 1.4269,  1.4269,  1.4440,  ...,  2.0948,  2.0948,  2.0948],\n",
      "          [ 1.3584,  1.3584,  1.3413,  ...,  2.0948,  2.0948,  2.0948],\n",
      "          [ 1.2899,  1.2728,  1.2557,  ...,  2.0948,  2.0948,  2.0948]],\n",
      "\n",
      "         [[-1.0203, -0.9153, -1.0203,  ...,  1.8508,  1.8508,  1.8508],\n",
      "          [-0.9853, -0.9678, -1.0728,  ...,  1.8508,  1.8508,  1.8508],\n",
      "          [-0.9503, -1.0378, -1.0903,  ...,  1.8508,  1.8508,  1.8508],\n",
      "          ...,\n",
      "          [ 1.1856,  1.1856,  1.2031,  ...,  2.1660,  2.1660,  2.1660],\n",
      "          [ 1.1155,  1.1155,  1.0980,  ...,  2.1660,  2.1660,  2.1660],\n",
      "          [ 1.0455,  1.0280,  1.0105,  ...,  2.1660,  2.1660,  2.1660]],\n",
      "\n",
      "         [[-1.0027, -0.8981, -0.9678,  ...,  2.1346,  2.1346,  2.1346],\n",
      "          [-0.9678, -0.9504, -1.0201,  ...,  2.1346,  2.1346,  2.1346],\n",
      "          [-0.9330, -1.0201, -1.0376,  ...,  2.1346,  2.1346,  2.1346],\n",
      "          ...,\n",
      "          [ 0.8099,  0.8099,  0.8274,  ...,  1.9951,  1.9951,  1.9951],\n",
      "          [ 0.7751,  0.7751,  0.7576,  ...,  1.9951,  1.9951,  1.9951],\n",
      "          [ 0.7054,  0.6879,  0.6705,  ...,  1.9951,  1.9951,  1.9951]]]])], 'imtk_gt_semantic_seg': [tensor([[[[[[10, 10, 10,  ...,  2,  2,  2],\n",
      "            [10, 10, 10,  ...,  2,  2,  2],\n",
      "            [10, 10, 10,  ...,  2,  2,  2],\n",
      "            ...,\n",
      "            [ 3,  3,  3,  ..., 24, 24, 24],\n",
      "            [ 3,  3,  3,  ..., 24, 24, 24],\n",
      "            [ 3,  3,  3,  ..., 24, 24, 24]]]]]], dtype=torch.uint8)]}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [6], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m data_loader \u001b[38;5;241m=\u001b[39m DataLoader(\n\u001b[1;32m      2\u001b[0m     viper,\n\u001b[1;32m      3\u001b[0m     collate_fn\u001b[38;5;241m=\u001b[39mpartial(collate, samples_per_gpu\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      4\u001b[0m )\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmade dl\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(data_loader):\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28mprint\u001b[39m(data)\n",
      "File \u001b[0;32m/srv/flash1/skareer6/miniconda3/envs/mmseg/lib/python3.8/site-packages/torch/utils/data/dataloader.py:681\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    678\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    679\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    680\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 681\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    682\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    683\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    684\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    685\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/srv/flash1/skareer6/miniconda3/envs/mmseg/lib/python3.8/site-packages/torch/utils/data/dataloader.py:721\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    719\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    720\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 721\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    722\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    723\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/srv/flash1/skareer6/miniconda3/envs/mmseg/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/srv/flash1/skareer6/miniconda3/envs/mmseg/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/coc/testnvme/skareer6/Projects/VideoDA/mmsegmentation/mmseg/datasets/viperSeq.py:115\u001b[0m, in \u001b[0;36mViperSeqDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    112\u001b[0m         imt_imtk_flow \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_train_img_no_flow(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimg_infos, idx, im_tk_infos\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpast_images)\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    114\u001b[0m         \u001b[38;5;66;03m# print(\"flow on\")\u001b[39;00m\n\u001b[0;32m--> 115\u001b[0m         imt_imtk_flow \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprepare_train_img\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimg_infos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mim_tk_infos\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpast_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflow_infos\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;66;03m# im_tk = self.prepare_train_img(self.past_images, idx)\u001b[39;00m\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;66;03m# for k, v in im_tk.items():\u001b[39;00m\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;66;03m#     im_t[k+\"_tk\"] = v\u001b[39;00m\n\u001b[1;32m    120\u001b[0m \n\u001b[1;32m    121\u001b[0m \u001b[38;5;66;03m# if self.use_flow:\u001b[39;00m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m imt_imtk_flow\n",
      "File \u001b[0;32m/coc/testnvme/skareer6/Projects/VideoDA/mmsegmentation/mmseg/datasets/viperSeq.py:249\u001b[0m, in \u001b[0;36mViperSeqDataset.prepare_train_img\u001b[0;34m(self, infos, idx, im_tk_infos, flow_infos)\u001b[0m\n\u001b[1;32m    244\u001b[0m \u001b[38;5;66;03m# print(\"gttk sem seg: \", torch.from_numpy(imtk[\"gt_semantic_seg\"][None, None, :, :]).shape)\u001b[39;00m\n\u001b[1;32m    245\u001b[0m \u001b[38;5;66;03m# print(\"gttk sem seg no wrapping: \", imtk[\"gt_semantic_seg\"][None, None, :, :].shape)\u001b[39;00m\n\u001b[1;32m    246\u001b[0m \u001b[38;5;66;03m# print(\"gttk sem seg no wrapping: \", imtk[\"gt_semantic_seg\"].shape)\u001b[39;00m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;66;03m# print(\"gt sem seg no wrapping: \", ims[\"gt_semantic_seg\"].shape)\u001b[39;00m\n\u001b[1;32m    248\u001b[0m imtk_gt \u001b[38;5;241m=\u001b[39m DataContainer(torch\u001b[38;5;241m.\u001b[39mfrom_numpy(imtk[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgt_semantic_seg\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, :, :]))\n\u001b[0;32m--> 249\u001b[0m flows \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpipeline\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mload_flow_pipeline\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresultsFlow\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# print(\"flows after load: \", flows[\"flow\"], type(flows[\"flow\"]))\u001b[39;00m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;66;03m# print(\"ims after load: \", ims[\"img\"], type(ims[\"img\"]))\u001b[39;00m\n\u001b[1;32m    252\u001b[0m ImsAndFlows \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmerge(ims, imtk, flows) \u001b[38;5;66;03m#TODO: concat the ims and flows\u001b[39;00m\n",
      "File \u001b[0;32m/coc/testnvme/skareer6/Projects/VideoDA/mmsegmentation/mmseg/datasets/pipelines/compose.py:41\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;124;03m\"\"\"Call function to apply transforms sequentially.\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \n\u001b[1;32m     33\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;124;03m   dict: Transformed data.\u001b[39;00m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[0;32m---> 41\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     43\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/coc/testnvme/skareer6/Projects/VideoDA/mmsegmentation/mmseg/datasets/pipelines/loading.py:166\u001b[0m, in \u001b[0;36mLoadFlowFromFile.__call__\u001b[0;34m(self, results)\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, results):\n\u001b[0;32m--> 166\u001b[0m     flow \u001b[38;5;241m=\u001b[39m \u001b[43mloadFlow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mosp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresults\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mflow_prefix\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresults\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mflow_info\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfilename\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    167\u001b[0m     results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mflow\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m flow\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mdict\u001b[39m(flow\u001b[38;5;241m=\u001b[39mflow)\n",
      "File \u001b[0;32m/coc/testnvme/skareer6/Projects/VideoDA/mmsegmentation/tools/aggregate_flows/flow/my_utils.py:77\u001b[0m, in \u001b[0;36mloadFlow\u001b[0;34m(im_path)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;124;03mArgs\u001b[39;00m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;124;03m    im_path: path of flow to load.\u001b[39;00m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;124;03mReturns\u001b[39;00m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;124;03m    flow with shape H, W, 2 (I think)\u001b[39;00m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     76\u001b[0m im \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(im_path)\n\u001b[0;32m---> 77\u001b[0m flow \u001b[38;5;241m=\u001b[39m \u001b[43mReadKittiPngFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m w, h, u, v, mask \u001b[38;5;241m=\u001b[39m ReadKittiPngFile(im_path)\n\u001b[1;32m     80\u001b[0m u \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(u)\u001b[38;5;241m.\u001b[39mreshape((h, w))\n",
      "File \u001b[0;32m/coc/testnvme/skareer6/Projects/VideoDA/mmsegmentation/tools/aggregate_flows/flow/util_flow.py:71\u001b[0m, in \u001b[0;36mReadKittiPngFile\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     68\u001b[0m mask \u001b[38;5;241m=\u001b[39m array\u001b[38;5;241m.\u001b[39marray(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m, [\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m*\u001b[39m width\u001b[38;5;241m*\u001b[39mheight\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m y, row \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(rows):\n\u001b[0;32m---> 71\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(width):\n\u001b[1;32m     72\u001b[0m         ind \u001b[38;5;241m=\u001b[39m width\u001b[38;5;241m*\u001b[39my\u001b[38;5;241m+\u001b[39mx\n\u001b[1;32m     73\u001b[0m         u[ind] \u001b[38;5;241m=\u001b[39m (row[\u001b[38;5;241m3\u001b[39m\u001b[38;5;241m*\u001b[39mx] \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m15\u001b[39m) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m64.0\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "data_loader = DataLoader(\n",
    "    viper,pdb\n",
    "    collate_fn=partial(collate, samples_per_gpu=1)\n",
    ")\n",
    "print(\"made dl\")\n",
    "for i, data in enumerate(data_loader):\n",
    "    print(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80313507-0677-4569-98fc-f86aaa0b72f1",
   "metadata": {},
   "source": [
    "## Regular Viper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02571155-15b2-499d-9739-9f6af6c9a237",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-15 10:44:20,379 - mmseg - INFO - Loaded 4959 images\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PL:  [{'type': 'LoadImageFromFile'}, {'type': 'LoadAnnotations'}, {'type': 'Resize', 'img_scale': (2048, 1024), 'ratio_range': (0.5, 2.0)}, {'type': 'RandomCrop', 'crop_size': (720, 1280), 'cat_max_ratio': 0.75}, {'type': 'RandomFlip', 'prob': 0.5}, {'type': 'PhotoMetricDistortion'}, {'type': 'Normalize', 'mean': [123.675, 116.28, 103.53], 'std': [58.395, 57.12, 57.375], 'to_rgb': True}, {'type': 'Pad', 'size': (720, 1280), 'pad_val': 0, 'seg_pad_val': 255}, {'type': 'DefaultFormatBundle'}, {'type': 'Collect', 'keys': ['img', 'gt_semantic_seg']}]\n",
      "type PL:  <class 'list'>\n",
      "type PL:  False\n"
     ]
    }
   ],
   "source": [
    "# dataset settings\n",
    "dataset_type = 'ViperDataset'\n",
    "data_root = '/srv/share4/datasets/VIPER/'\n",
    "\n",
    "#imagenet values\n",
    "img_norm_cfg = dict(\n",
    "    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\n",
    "\n",
    "#crop size from the da-vsn paper code\n",
    "crop_size = (720, 1280)\n",
    "train_pipeline = [\n",
    "    dict(type='LoadImageFromFile'),\n",
    "    dict(type='LoadAnnotations'),\n",
    "    dict(type='Resize', img_scale=(2048, 1024), ratio_range=(0.5, 2.0)),\n",
    "    dict(type='RandomCrop', crop_size=crop_size, cat_max_ratio=0.75),\n",
    "    dict(type='RandomFlip', prob=0.5),\n",
    "    dict(type='PhotoMetricDistortion'),\n",
    "    dict(type='Normalize', **img_norm_cfg),\n",
    "    dict(type='Pad', size=crop_size, pad_val=0, seg_pad_val=255),\n",
    "    dict(type='DefaultFormatBundle'),\n",
    "    dict(type='Collect', keys=['img', 'gt_semantic_seg']),\n",
    "]\n",
    "test_pipeline = [\n",
    "    dict(type='LoadImageFromFile'),\n",
    "    dict(\n",
    "        type='MultiScaleFlipAug',\n",
    "        img_scale=(2048, 1024),\n",
    "        # img_ratios=[0.5, 0.75, 1.0, 1.25, 1.5, 1.75],\n",
    "        flip=False,\n",
    "        transforms=[\n",
    "            # dict(type='Resize', keep_ratio=True),\n",
    "            # dict(type='RandomFlip'),\n",
    "            dict(type='Normalize', **img_norm_cfg),\n",
    "            dict(type='ImageToTensor', keys=['img']),\n",
    "            dict(type='Collect', keys=['img']),\n",
    "        ])\n",
    "]\n",
    "\n",
    "viper = ViperDataset(\n",
    "        data_root=data_root,\n",
    "        img_dir='val/img',\n",
    "        ann_dir='val/cls',\n",
    "        split='splits/val.txt',\n",
    "        pipeline=train_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9af76622-b9db-476e-aedf-f2f478adf1ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "made dl\n",
      "{'img_metas': DataContainer([[{'filename': '/srv/share4/datasets/VIPER/val/img/001/001_00010.jpg', 'ori_filename': '001/001_00010.jpg', 'ori_shape': (1080, 1920, 3), 'img_shape': (720, 1280, 3), 'pad_shape': (720, 1280, 3), 'scale_factor': array([1.1109375, 1.1111112, 1.1109375, 1.1111112], dtype=float32), 'flip': False, 'flip_direction': 'horizontal', 'img_norm_cfg': {'mean': array([123.675, 116.28 , 103.53 ], dtype=float32), 'std': array([58.395, 57.12 , 57.375], dtype=float32), 'to_rgb': True}}], [{'filename': '/srv/share4/datasets/VIPER/val/img/001/001_00020.jpg', 'ori_filename': '001/001_00020.jpg', 'ori_shape': (1080, 1920, 3), 'img_shape': (720, 1280, 3), 'pad_shape': (720, 1280, 3), 'scale_factor': array([0.85572916, 0.85555553, 0.85572916, 0.85555553], dtype=float32), 'flip': True, 'flip_direction': 'horizontal', 'img_norm_cfg': {'mean': array([123.675, 116.28 , 103.53 ], dtype=float32), 'std': array([58.395, 57.12 , 57.375], dtype=float32), 'to_rgb': True}}]]), 'img': DataContainer([tensor([[[[-1.2788, -1.2959, -1.3130,  ...,  1.2385,  1.2385,  1.2385],\n",
      "          [-1.2788, -1.2788, -1.2959,  ...,  1.2385,  1.2385,  1.2385],\n",
      "          [-1.2617, -1.2617, -1.2788,  ...,  1.2385,  1.2385,  1.2385],\n",
      "          ...,\n",
      "          [-0.1657, -0.0801,  0.0741,  ...,  0.2967,  0.3481,  0.3994],\n",
      "          [-0.0287,  0.0227,  0.1597,  ...,  0.2282,  0.3652,  0.4166],\n",
      "          [ 0.0741,  0.1083,  0.2282,  ...,  0.1939,  0.2796,  0.3138]],\n",
      "\n",
      "         [[-1.1604, -1.1779, -1.1954,  ...,  1.4482,  1.4482,  1.4482],\n",
      "          [-1.1604, -1.1604, -1.1779,  ...,  1.4482,  1.4482,  1.4482],\n",
      "          [-1.1429, -1.1429, -1.1604,  ...,  1.4482,  1.4482,  1.4482],\n",
      "          ...,\n",
      "          [-0.1275, -0.0399,  0.1176,  ...,  0.3102,  0.3627,  0.4153],\n",
      "          [-0.0049,  0.0476,  0.2052,  ...,  0.2402,  0.3627,  0.4328],\n",
      "          [ 0.1001,  0.1352,  0.2577,  ...,  0.2052,  0.2927,  0.3277]],\n",
      "\n",
      "         [[-0.9853, -1.0027, -1.0201,  ...,  1.7511,  1.7511,  1.7511],\n",
      "          [-0.9853, -0.9853, -1.0027,  ...,  1.7511,  1.7511,  1.7511],\n",
      "          [-0.9678, -0.9678, -0.9853,  ...,  1.7511,  1.7511,  1.7511],\n",
      "          ...,\n",
      "          [-0.0964,  0.0082,  0.1302,  ...,  0.2696,  0.3219,  0.3742],\n",
      "          [ 0.0256,  0.0605,  0.1825,  ...,  0.1999,  0.3219,  0.4091],\n",
      "          [ 0.0953,  0.1128,  0.2173,  ...,  0.1651,  0.2522,  0.2871]]]]), tensor([[[[ 2.2489,  2.2489,  2.2489,  ...,  1.8379,  1.5810,  1.1872],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ..., -0.6965, -0.6794, -0.6965],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ..., -0.5938, -0.5938, -0.6965],\n",
      "          ...,\n",
      "          [ 1.3755,  1.3242,  1.2728,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 1.1358,  1.0159,  0.9646,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 0.8276,  0.7591,  0.8276,  ...,  2.2489,  2.2489,  2.2489]],\n",
      "\n",
      "         [[ 2.4286,  2.4286,  2.4286,  ...,  2.0609,  1.7458,  1.3606],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ..., -0.5826, -0.4776, -0.5826],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ..., -0.4601, -0.4601, -0.5126],\n",
      "          ...,\n",
      "          [ 1.1506,  1.0980,  1.0455,  ...,  2.1134,  2.1134,  2.0784],\n",
      "          [ 0.9055,  0.8179,  0.7479,  ...,  2.3410,  2.3410,  2.3410],\n",
      "          [ 0.5903,  0.5203,  0.5903,  ...,  2.3410,  2.3410,  2.2710]],\n",
      "\n",
      "         [[ 2.6400,  2.6400,  2.6400,  ...,  2.2914,  2.0125,  1.6291],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ..., -0.3055, -0.2358, -0.3055],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ..., -0.1835, -0.1835, -0.3404],\n",
      "          ...,\n",
      "          [ 1.2631,  1.1934,  1.1759,  ...,  2.1520,  2.1520,  2.1346],\n",
      "          [ 1.0017,  0.9319,  0.8448,  ...,  2.3960,  2.3960,  2.3960],\n",
      "          [ 0.7228,  0.6531,  0.7228,  ...,  2.3960,  2.3960,  2.3263]]]])]), 'gt_semantic_seg': DataContainer([tensor([[[[10, 10, 10,  ...,  2,  2,  2],\n",
      "          [10, 10, 10,  ...,  2,  2,  2],\n",
      "          [10, 10, 10,  ...,  2,  2,  2],\n",
      "          ...,\n",
      "          [10, 10, 10,  ...,  3,  3,  3],\n",
      "          [10, 10, 10,  ...,  3,  3,  3],\n",
      "          [10, 10, 10,  ...,  3,  3,  3]]]]), tensor([[[[ 2,  2,  2,  ..., 10, 10,  2],\n",
      "          [ 2,  2,  2,  ..., 10, 10, 10],\n",
      "          [ 2,  2,  2,  ..., 10, 10, 10],\n",
      "          ...,\n",
      "          [ 3,  3,  3,  ...,  3,  3,  3],\n",
      "          [ 3,  3,  3,  ...,  3,  3,  3],\n",
      "          [ 3,  3,  3,  ...,  3,  3,  3]]]])])}\n",
      "torch.Size([1, 1, 720, 1280])\n",
      "torch.Size([1, 3, 720, 1280])\n"
     ]
    }
   ],
   "source": [
    "data_loader = DataLoader(\n",
    "    viper,\n",
    "    batch_size=2,\n",
    "    collate_fn=partial(collate, samples_per_gpu=1)\n",
    ")\n",
    "print(\"made dl\")\n",
    "for i, data in enumerate(data_loader):\n",
    "    # for k, v in data.items():\n",
    "    print(data)\n",
    "    print(data[\"gt_semantic_seg\"].data[1].shape)\n",
    "    print(data[\"img\"].data[0].shape)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5398b38-daa4-46a7-a2e2-f6e0e55e0079",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:mmseg]",
   "language": "python",
   "name": "conda-env-mmseg-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
